{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1. Installation\n",
    "\n",
    "//install libraries\n",
    "import org.archive.archivespark._\n",
    "import org.archive.archivespark.functions._\n",
    "import org.archive.archivespark.specific.warc._\n",
    "\n",
    "// data files - generic path from docker run -v\n",
    "val cdxPath = \"/data/arc_cdx/*.cdx\"\n",
    "val warcPath = \"/data/warc\"\n",
    "\n",
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "\n",
    "val session = spark.newSession\n",
    "\n",
    "import org.apache.spark.sql.functions.count\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// collect all records\n",
    "\n",
    "val r = ArchiveSpark.load(WarcSpec.fromFiles(cdxPath, warcPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72235608"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2.2 count all captures\n",
    "// need r.mimetype not started by 1995\n",
    "r.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val r1996 = r.filter(r => r.timestamp.startsWith(\"1996\"))\n",
    "val r1997 = r.filter(r => r.timestamp.startsWith(\"1997\"))\n",
    "val r1998 = r.filter(r => r.timestamp.startsWith(\"1998\"))\n",
    "val r1999 = r.filter(r => r.timestamp.startsWith(\"1999\"))\n",
    "val r2000 = r.filter(r => r.timestamp.startsWith(\"2000\"))\n",
    "val r2001 = r.filter(r => r.timestamp.startsWith(\"2001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1996\n",
    "val m = r1996.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "\n",
    "//val err = df.select(df(\"status\")).distinct\n",
    "val err2 = df.groupBy(\"status\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|status|\n",
      "+------+\n",
      "|   500|\n",
      "|   200|\n",
      "|   302|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "err.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|status| count|\n",
      "+------+------+\n",
      "|   500|    32|\n",
      "|   200|161192|\n",
      "|   302|    94|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "err2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1997\n",
    "val m = r1997.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "\n",
    "val err = df.select(df(\"status\")).distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|status|\n",
      "+------+\n",
      "|   200|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 1998\n",
    "err.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val err2 = df.groupBy(\"status\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|status|  count|\n",
      "+------+-------+\n",
      "|   200|2781718|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 1997\n",
    "err2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|status|  count|\n",
      "+------+-------+\n",
      "|   300|     26|\n",
      "|   301|  16986|\n",
      "|   200|2216746|\n",
      "|   302|  16764|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 1998\n",
    "\n",
    "val m = r1998.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "\n",
    "val err2 = df.groupBy(\"status\").count()\n",
    "err2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|status|  count|\n",
      "+------+-------+\n",
      "|   300|    598|\n",
      "|   406|    224|\n",
      "|   301| 157104|\n",
      "|   400|    702|\n",
      "|   403|  13560|\n",
      "|   404| 496410|\n",
      "|   408|      6|\n",
      "|   200|3696468|\n",
      "|   303|     12|\n",
      "|   302| 210514|\n",
      "|   410|      6|\n",
      "|   407|     10|\n",
      "|   401|   2934|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 1999\n",
    "\n",
    "val m = r1999.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "\n",
    "val err2 = df.groupBy(\"status\").count()\n",
    "err2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|status|   count|\n",
      "+------+--------+\n",
      "|   300|    1078|\n",
      "|   406|    2622|\n",
      "|   500|    1282|\n",
      "|   504|       2|\n",
      "|   502|      54|\n",
      "|   503|      42|\n",
      "|   301|  195852|\n",
      "|   400|    1674|\n",
      "|   403|   60748|\n",
      "|   404| 1379312|\n",
      "|   408|     344|\n",
      "|   411|       2|\n",
      "|   200|12761456|\n",
      "|   303|     612|\n",
      "|   204|      10|\n",
      "|   302|  879124|\n",
      "|   405|       2|\n",
      "|   401|   16170|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 2000\n",
    "\n",
    "val m = r2000.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "\n",
    "val err2 = df.groupBy(\"status\").count()\n",
    "err2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|status|   count|\n",
      "+------+--------+\n",
      "|   300|    3678|\n",
      "|   406|     882|\n",
      "|   501|      54|\n",
      "|   206|       6|\n",
      "|   500|   33756|\n",
      "|   402|       2|\n",
      "|   504|      66|\n",
      "|   502|    1344|\n",
      "|   503|    8116|\n",
      "|   301|  588136|\n",
      "|   400|    4348|\n",
      "|   403|  100932|\n",
      "|   404| 7061930|\n",
      "|   408|     104|\n",
      "|   200|36344428|\n",
      "|   303|     112|\n",
      "|   204|      76|\n",
      "|   413|       2|\n",
      "|   302| 2990158|\n",
      "|   405|      40|\n",
      "+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 2001\n",
    "\n",
    "val m = r2001.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "\n",
    "val err2 = df.groupBy(\"status\").count()\n",
    "err2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|status|   count|\n",
      "+------+--------+\n",
      "|   300|    3678|\n",
      "|   406|     882|\n",
      "|   501|      54|\n",
      "|   206|       6|\n",
      "|   500|   33756|\n",
      "|   402|       2|\n",
      "|   504|      66|\n",
      "|   502|    1344|\n",
      "|   503|    8116|\n",
      "|   301|  588136|\n",
      "|   400|    4348|\n",
      "|   403|  100932|\n",
      "|   404| 7061930|\n",
      "|   408|     104|\n",
      "|   200|36344428|\n",
      "|   303|     112|\n",
      "|   204|      76|\n",
      "|   413|       2|\n",
      "|   302| 2990158|\n",
      "|   405|      40|\n",
      "|   410|      10|\n",
      "|   401|   24536|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "err2.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArchiveSpark",
   "language": "",
   "name": "archivespark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
